---
title: Multicluster PKI
description: Shows how to use Citadel to construct a multicluster PKI.

weight: 90

---
{% include home.html %}

This task shows how to use Citadel to construct a PKI
([public key infrastructure](https://en.wikipedia.org/wiki/Public_key_infrastructure))
that works across multiple Istio clusters.
In this architecture, one Citadel runs in a dedicated Kubernetes cluster acts as the root CA.
It issues and rotates intermediate CA certificates for Citadel instances in each Istio workload cluster.
Each Istio cluster has a Citadel issuing certificates to workloads in the cluster.

This is an alpha feature and currently it has the following caveats:

* CA certificate revocation is not supported.
* [X.509 certificate name constraints](https://tools.ietf.org/html/rfc5280#section-4.2.1.10) are not supported.
* This architecture is subject to change in the future.
* This task does not solve the multicluster service discovery and secure naming probblems, so extra work is needed
  to support direct workload-to-workload communication across clusters.

Citadel acting as intermediate CA can automatically communicate with an upstream Citadel to rotate its signing certificate.
In this task, you will set up a two-level PKI involving one Citadel as the online root CA and one
Citadel as the intermediate CA.
The architecture shown in this task can be extended to have multiple levels of intermediate CAs,
and each upstream Citadel can provision certificates for multiple downstream Citadels.

* Note: This task offers a different solution than the
  [multicluster installation instructions]({{home}}docs/setup/kubernetes/multicluster-install.html).

## Before you begin

* In the cluster running the workloads, set up Istio by following the instructions in the
  [quick start]({{home}}/docs/setup/kubernetes/quick-start.html) with global mutual TLS enabled:

    ```command
    $ kubectl apply -f install/kubernetes/istio-demo-auth.yaml
    ```
    _**OR**_

    Using [Helm](/docs/setup/kubernetes/helm-install/) with `global.mtls.enabled` to `true`.

## PKI archtecture

The PKI archtecture of this task is shown in the following graph:

{% include image.html width="80%" ratio="56.25%"
    link="./img/multicluster-pki.svg"
    alt="Multicluster PKI example."
    caption="Multicluster PKI example"
    %}

In the task, the Citadel deployed in the cluster running the workloads is named as _Cluster Citadel_.
It acts as the intermediate CA issuing workload certificates. There is a _Standalone Citadel_ that runs
in a dedicated cluster. It is recommended to run the Standalone Citadel in a dedicated cluster for security reasons.
The standalone Citadel acts as an online root CA to issue certificates to the Cluster Citadel.

The Cluster Citadel automatcally rotates its certificate by interacting with the Standalone Citadel through a gRPC
port over mutual TLS. The Standalone Citadel exposes its certificate signing service via a public IP.
In the workload cluster,
the public IP of the Standalone Citadel is defined as an endpoint and a service for the Cluster Citadel to access.
We plug the CA key/certificate (generated by the Standalone Citadel) and the root certificate into the Cluster Citadel.
Both the Cluster Citadel and the Standalone Citadel trust the root certificate.
For the authentication between the Cluster Citadel and the Standalone Citadel.

> Note: in the long term, Citadel will support authenticating subordinate Citadels through platform credentials
(such as GCP credentials), HSM, etc.

## Setting up Standalone Citadel

1. (If you don't already have a dedicated cluster for the Standalone Citadel)
Create a cluster for the Standalone Citadel (a small cluster with one node should be good enough).

   The following command is an example to create a 1-node cluster in GCP, and binds the current operator to the cluster
admin role.

   ```command
   $ PROJECT=my-istio-project  # Set your GCP project
   $ ZONE=us-west1-a           # Set the zone for the k8s cluster
   $ gcloud container clusters create root-citadel-cluster --project $PROJECT --zone $ZONE \
   --machine-type=n1-highcpu-2 --num-nodes=1 --no-enable-legacy-authorization
   $ kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin \
   --user="$(gcloud config get-value core/account)"
   ```

1. In the cluster for Standalone Citadel, set up the Citadel service:

   ```command
   $ kubectl apply -f install/kubernetes/istio-citadel-standalone.yaml
   ```

   This command creates the "istio-system" namespace, creates a service account, sets the role binding,
   deploys the standalone Citadel and exposes it through a LoadBalencer service.
   The deployed Istio Citadel opens a gRPC port 8060, and the server certificate uses the identity
   `istio-standalone-citadel`.
   It acts as a self-signed root CA, and the first certificates issued for intermediate CAs
   has the lifetime of 21 hours.

1. Set the `CITADEL_IP` to the external IP of Standalone Citadel:

   ```command
   $ CITADEL_IP=`kubectl get svc standalone-citadel-ilb -n istio-system -o \
   jsonpath='{.status.loadBalancer.ingress[0].ip}'`
   $ echo $CITADEL_IP
   ```

   > Note: if `CITADEL_IP` is empty, wait some time and run the command again.

1. Suppose the Cluster Citadel is using the `default` service account in the `default` namespace.
   Download the certificate (ignore the output text):

   ```command
   $ install/tools/setupMeshEx.sh machineCerts default default all
   ```

   Check the certificate for Cluster Citadel:

   ```command
   $ openssl x509 -in cert-chain.pem -noout -text
   ...
     X509v3 Basic Constraints: critical
         CA:TRUE
     X509v3 Subject Alternative Name:
         URI:spiffe://cluster.local/ns/default/sa/default
   ...
   ```

   Copy the PEM files to `/tmp` directory:

   ```command
   $ cp cert-chain.pem /tmp/cert-chain.pem
   $ mv cert-chain.pem /tmp/ca-cert.pem
   $ mv key.pem /tmp/ca-key.pem
   $ mv root-cert.pem /tmp/root-cert.pem
   ```

## Associate Cluster Citadel with Standalone Citadel

1. Switch to the cluster that runs the workloads.

1. Create the secret for Cluster Citadel to load:

   ```command
   $ kubectl create secret generic cacerts -n istio-system --from-file=/tmp/ca-cert.pem --from-file=/tmp/ca-key.pem \
   --from-file=/tmp/root-cert.pem --from-file=/tmp/cert-chain.pem
   ```

1. Define an endpoint and service for Standalone Citadel.

   ```command
   $ cat <<EOF | kubectl create -f -
   apiVersion: v1
   kind: Service
   metadata:
     name: istio-standalone-citadel
     namespace: istio-system
   spec:
     ports:
     - port: 8060
       protocol: TCP
       targetPort: 8060
   ---
   kind: Endpoints
   apiVersion: v1
   metadata:
     name: istio-standalone-citadel
     namespace: istio-system
   subsets:
     - addresses:
         - ip: $CITADEL_IP
       ports:
         - port: 8060
   EOF
   ```

1. Add a few lines to `install/kubernetes/istio-citadel-plugin-certs.yaml` to provision certificates from
Standalone Citadel:

   ```yaml
         ...
         command: ["/usr/local/bin/istio_ca"]
           args:
             ...
             - --upstream-ca-address=istio-standalone-citadel:8060
             - --org=cluster-citadel
             - --requested-ca-cert-ttl=48h
             - --workload-cert-ttl=21h
         ...
   ```

   With this configuration, Citadel can request certificates with 48 hour lifetime, and it issues workload certificates
   with 21 hour lifetime.

1. Deploy the modified Citadel yaml file.

   ```command
   $ kubectl apply -f install/kubernetes/istio-citadel-plugin-certs.yaml
   ```

   This will restart Citadel with the new plugged in certificate.

## Verification

1. Verify the rotation takes place by checking the logs in subordinate Citadel.

   ```command
   $ kubectl logs -l istio=citadel -n istio-system
   ```


1. Verify the by checking the default service account certificate

   ```command
   $ install/tools/setupMeshEx.sh machineCerts default default all
   $ diff root-cert.pem /tmp/root-cert.pem # Expect empty output.
   ```

